{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "task5_text_transformer.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLXypDOdLRcn",
        "colab_type": "text"
      },
      "source": [
        "# Transformer, Self-Attention и моделирование языка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:04.225361Z",
          "start_time": "2019-11-05T18:27:04.223470Z"
        },
        "id": "czZzhzKYLRcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5399bf0-9659-451a-8478-ffe92a61e7b4"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git\n",
        "import sys; sys.path.append('/content/stepik-dl-nlp')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'stepik-dl-nlp' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iolpPp6dLuOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "49d37992-981c-4c7e-9d86-e9b301bf7d89"
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: youtokentome in /usr/local/lib/python3.6/dist-packages (1.0.6)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcrhVa1TL2lt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "73a18f57-b29f-4c27-fbf6-e64781f580b7"
      },
      "source": [
        "!pip install spacy_udpipe"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy_udpipe in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: ufal.udpipe>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy_udpipe) (1.2.0.3)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy_udpipe) (2.1.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (0.6.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (0.9.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (1.17.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (2.21.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (1.0.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (0.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (2.0.3)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy_udpipe) (2.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy>=2.1.0->spacy_udpipe) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->spacy_udpipe) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->spacy_udpipe) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->spacy_udpipe) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.0->spacy_udpipe) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:53.780539Z",
          "start_time": "2019-11-05T18:27:52.444607Z"
        },
        "id": "aIRjE7yeLRcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1825ff29-cdbb-4422-93c4-42de2765e970"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import youtokentome as yttm\n",
        "\n",
        "import dlnlputils\n",
        "from dlnlputils.data import tokenize_corpus, build_vocabulary, \\\n",
        "    save_texts_to_file, LanguageModelDataset, load_war_and_piece_chunks, \\\n",
        "    GreedyGenerator, BeamGenerator\n",
        "from dlnlputils.pipeline import train_eval_loop, init_random_seed\n",
        "from dlnlputils.base import get_params_number\n",
        "\n",
        "init_random_seed()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsuANqluLRc5",
        "colab_type": "text"
      },
      "source": [
        "## Загрузка текстов и разбиение на обучающую и тестовую подвыборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:55.233798Z",
          "start_time": "2019-11-05T18:27:55.197616Z"
        },
        "id": "g3zunruYLRc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a8ce0dc-2d23-4125-a6c3-34a4bdafacac"
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab, добавьте в начало пути /content/stepik-dl-nlp\n",
        "all_chunks = load_war_and_piece_chunks('/content/stepik-dl-nlp/datasets/war_and_peace.txt')\n",
        "len(all_chunks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:55.402080Z",
          "start_time": "2019-11-05T18:27:55.379575Z"
        },
        "id": "w9U13Td9LRdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a3e50cf5-ba68-488d-ab8b-015219dadcb2"
      },
      "source": [
        "print(all_chunks[10])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "у нее был грипп, как она говорила (грипп был тогда новое\n",
            "слово, употреблявшееся только редкими). В записочках, разосланных утром с\n",
            "красным лакеем, было написано без различия во всех:\n",
            "  \"Si vous n'avez\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:55.954154Z",
          "start_time": "2019-11-05T18:27:55.919185Z"
        },
        "id": "PuSiOjBOLRdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "16f6a30f-3607-4a66-9f48-64ef3e0c1392"
      },
      "source": [
        "np.random.shuffle(all_chunks)\n",
        "\n",
        "TRAIN_SPLIT = int(len(all_chunks) * 0.7)\n",
        "train_texts = all_chunks[:TRAIN_SPLIT]\n",
        "test_texts = all_chunks[TRAIN_SPLIT:]\n",
        "\n",
        "print('Размер обучающей выборки', len(train_texts))\n",
        "print('Размер валидационной выборки', len(test_texts))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер обучающей выборки 5583\n",
            "Размер валидационной выборки 2393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HKxM2g5LRdQ",
        "colab_type": "text"
      },
      "source": [
        "## Токенизация корпуса с помощью BPE\n",
        "\n",
        "BPE - Byte Pair Encoding\n",
        "\n",
        "YouTokenToMe - быстрая реализация BPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:56.412237Z",
          "start_time": "2019-11-05T18:27:56.386089Z"
        },
        "id": "2aG61OwsLRdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab, добавьте в начало пути /content/stepik-dl-nlp\n",
        "BPE_MODEL_FILENAME = '/content/stepik-dl-nlp/models/war_and_peace_bpe.yttm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:56.928780Z",
          "start_time": "2019-11-05T18:27:56.696400Z"
        },
        "id": "ZXz2E0PQLRdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab, добавьте в начало пути /content/stepik-dl-nlp\n",
        "TRAIN_TEXTS_FILENAME = '/content/stepik-dl-nlp/datasets/war_and_peace_bpe_train.txt'\n",
        "save_texts_to_file(train_texts, TRAIN_TEXTS_FILENAME)\n",
        "yttm.BPE.train(data=TRAIN_TEXTS_FILENAME, vocab_size=1000, model=BPE_MODEL_FILENAME);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:57.767294Z",
          "start_time": "2019-11-05T18:27:57.731252Z"
        },
        "id": "Zf_FxOstLRde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = yttm.BPE(BPE_MODEL_FILENAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:57.897826Z",
          "start_time": "2019-11-05T18:27:57.874631Z"
        },
        "id": "ObW8DM8DLRdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b5a69940-91c4-4489-cdb7-f6a52da56bb7"
      },
      "source": [
        "print(' '.join(tokenizer.vocab()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD> <UNK> <BOS> <EOS> ▁ о а е и н т с л р в к , д м у п я г ь ы з б . ч й - ж ш e х ю s ц a n r i u o t щ э П l Н ф А В m d c О ? ! К Д Б p М v Р \" ) С ( ' ; И Т ё 1 h : Я 2 q f Г ъ b g Ч Э 0 3 Е 5 ] [ j 4 I z Л З 6 8 M A 9 7 У Ж V L x X Ф Ш y C Х J B P D E N S k Ц R Q O T ` w Ю H U F G K Ь W Й * & # Щ Z / ▁с ▁п ▁в ▁н то ▁о ▁и ▁к го ал ра ст но ▁- ▁по ен ▁д ер ел ▁б ро ▁не ко во ка ▁ч ▁м ри ▁на ло ть на ли ла ▁з ▁е ▁у ▁т ре ва ни ся сь ак ▁что ру ет ▁ко ▁бы ми ны ня да ▁то ди хо ▁за ▁го ем ▁г ▁он ол ени ▁от ки ви ну каз е, ▁э та ▁П ти ши ▁при ▁вы ▁ра му ▁Н ▁ж ов ▁вс ле ▁А до ▁В ▁про ▁мо ля ▁как мо ▁во казал ры ▁его ма ▁об сто ▁это ль й, ▁сказал ере не ▁а ▁до ▁О ▁я ▁К ▁кото ▁сво ▁кня ▁Д м, у, ше ▁Б али по чи ▁но сти ▁ни си ча ста ель ▁из ве лу ала де ▁Ан вори ▁М ▁под ▁ка ▁d .. ша ... за ска жи ще es я, лся ▁со че лы зь сть ско ou ▁ли ▁хо ▁ви ▁ст ень ▁ру ря енно ▁Пь ▁так ме ты ▁p ▁Р ги га дел лю сно re же ▁раз ▁( со те ду ку ▁се ски ▁c ▁С ▁ва вши ▁все тель бе en вал ▁l ▁дру ▁было ▁И on ▁говори ▁пос гда ту ▁сто ели щи ать лько ▁бу вы ▁Пьер ▁пере ▁Ро дре ▁ему ▁Т дно ▁пре ▁Андре ▁a вер ю, би ство ез ▁са ▁ф вая ▁Росто ▁Он ▁зна ар сп ▁она ▁которы а, ▁сп ▁m ▁был ▁же ▁всё ▁гла чал сь, бо ды ▁ми ▁те ву й. ▁ду er жени ▁голо х, ▁ве ▁(сно ▁князь ▁(сноска шел фи ба ▁лю ▁ста мот бы ▁лиц ▁бол ▁вз ▁На е. жа кой ▁Бо ть, ело ▁та енны ▁de ▁Я в, et го, нц ми, ▁s -то елов ai ▁си ало ▁да ▁гра ▁только т, ела гля ▁свое ▁ш ▁1 ▁оп м. ться ходи ▁буд qu са ха ▁которо жно ▁v гу ▁\" лов ▁ты шь ous ера ▁улы тельно ▁Кня ▁ее ▁еще ▁рас ▁n рем ▁ро вно ▁ме ▁Г к, пи ный нно ▁ре ▁пол ▁обра ▁им ▁qu ▁свои я. дь елове ▁и, жал фиц ясь ным ерь ▁челове ▁глаза оло ▁оста ▁Дени сов дя an ▁По ▁себ ▁слу па ▁ле ▁жи ▁боль су ▁для ▁ц ▁чу ка, ▁сказала ять ался аль e, ет, вля ▁Не рел ▁ло на, нул ▁Ч ▁ма лась бу ▁Э ▁t ман ей ▁была роси ▁него ск нцу ▁после гра ▁были ▁Ростов мы ▁эти ▁мне ▁сол ▁Андрей ▁офиц ▁врем ща ех ▁княз ▁х ▁бо ▁пер ▁говорил и, ri ▁он, нима ств ▁Е ▁мог ранцу ▁ком те, сту вать ▁дол н, le ят лись ▁бе ▁граф ▁Князь чень ▁вер ▁Доло ные шо ▁мы ▁сло ▁лицо ▁исп ▁[ ▁Долохо ва, чно ему ▁улыб ▁сдел ▁му ▁ча вор ▁пред ▁одно te ▁f зи перь ▁моло ▁2 ▁солда ▁мен руг ▁комна ▁смот нулся ца eu жет ения ▁et вет нов ражени ▁когда oi чего ▁стра ▁чтобы ▁Денисов ▁Ни ю. казы ▁хот ▁pa ки, зы ▁уже ▁кра ▁они ▁ба ▁хоро ались ком ного ▁Ва ▁пи вше дин ав се вст ▁друго ▁очень спо ▁францу ков лен ▁будто ▁вас ▁су ал, ▁княж ▁Ми ▁Но зна х. ▁который om ▁ту ▁перед ▁отве том нт ▁пра об ne ▁Ку est ▁од ▁пу ▁Она ▁Анна нови ▁теперь ▁опять ▁сов ная говори ▁Л ▁этого ▁де ▁Ната ▁vous ▁поло ▁стоя арь зов ▁гу ▁que ▁j ющи вой ▁воз ▁себя ной вство ных ение ▁дел ▁жен ем, нь ▁Что ▁мину стви ▁спроси ▁З дет ▁офицер ent ский ▁этот ку, ▁то, ▁кри ▁Марь лыш ▁ар ▁вп ▁ожи ▁ку зо ния ▁Во дол ми. ▁la ▁ch ▁le ▁Нико ▁поч ную ▁двер ▁подо ▁обе ▁коман сили ▁или ке л, ▁Это me ▁неп жели ▁вой у. ▁чем сте му, ние ют мал ▁ла ▁нес ▁разго ▁Мо вали is ▁Вы енер ▁Миха ▁взгля ▁которые ▁зак ▁сы il дар ▁меня он стро ▁M ую кры ее ▁продол ▁мал сы ▁пла вший кон ▁ничего друг ва. ▁Ба ▁Михай ▁сле ром жен ▁огля ▁види ▁дело ▁Бори ▁ша стоя ров ▁быть но, ся, ▁зам воль ▁Со our ▁себе пра ского ▁Никола ▁Куту кая ▁без казать ▁время ными вала in ▁друг на. ▁обрати ▁Как ▁что-то ▁Ну, ▁чи кий лаго ▁князя вл ▁их ▁Пав ▁сер ▁своего ▁вес ▁вот ▁Михайлов соб рая ▁бра ▁че ▁всех ниц ▁нас ▁жиз ais ▁свою ехал ▁Ко ▁каз ▁само кра ▁он. д, про ▁тем ▁молодо сколько ▁u ▁b ▁A ere дер ▁пе ▁команди вшись ▁останови ▁лоша сты ▁взя ▁генер ра, стно да, ▁доро us жд ▁может ▁Да ▁сидел ▁сторо ▁надо юще ▁тре ть. чь ▁ну ▁чувство ▁госу ▁Пьера ▁мол ▁малень ▁Наташа кое им ▁вдруг it ▁l' ли, мер ▁Багра вого ▁л ним ▁непри ▁други ▁спросил ▁будет ▁пото и. ▁своей ▁княги кого ez ▁Баграти ▁доб ▁па ▁люб жала ▁Ж пу ▁расс ▁арми ▁рука лось ▁Павлов ▁Васили ▁ок ▁видел ▁У оль дом ▁впере ▁начал ▁особ ▁где кто тер ▁вст шь, ▁сча ▁бле дал ▁mon жду ▁сме ▁прои ливо ▁вам ерез 'est вя ▁мой ▁Ту ▁рус ▁день ▁ши ▁ди ственно ▁g дро ▁улыба ▁дума ку. ▁лу ▁3 ▁кре ▁его. ете виц каза стя шая ▁отвечал ▁всегда цо ▁com ch ▁Пьер, ▁ско res шла жу ▁более ▁выражени ▁есть ны, ской ▁благо гла тя ▁сам ▁того, ▁вели ▁спо елы та, ▁сла ы,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:58.100551Z",
          "start_time": "2019-11-05T18:27:58.075268Z"
        },
        "scrolled": false,
        "id": "Cw47A0TqLRdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7dd4c691-cdab-4530-b12c-cf7c11a4784c"
      },
      "source": [
        "print(tokenizer.encode(train_texts[:1]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[210, 238, 244, 13, 317, 16, 147, 200, 12, 265, 35, 161, 337, 490, 203, 269, 447, 4, 111, 111, 96, 27, 415, 148, 176, 551, 201, 726, 199, 161, 848, 889, 772, 23, 16, 690, 179, 585, 18, 154, 412, 19, 382, 157, 186, 635, 10, 518, 774, 363, 670, 157, 793, 37, 7, 426, 791, 186, 635, 10, 518, 774, 650, 25, 988, 206, 186, 13, 201, 8, 149, 474, 17, 275, 31, 23, 8, 34, 444]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:59.729717Z",
          "start_time": "2019-11-05T18:27:59.551045Z"
        },
        "id": "k8hODCsXLRdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_token_ids = tokenizer.encode(train_texts, bos=True, eos=True)\n",
        "test_token_ids = tokenizer.encode(test_texts, bos=True, eos=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:00.401753Z",
          "start_time": "2019-11-05T18:27:59.731680Z"
        },
        "id": "7ET_epn7LRd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "ae1ad8bd-9b29-415c-e0ed-4b59512a88a8"
      },
      "source": [
        "plt.hist([len(sent) for sent in train_token_ids], bins=30)\n",
        "plt.title('Распределение длин фрагментов в токенах')\n",
        "plt.yscale('log');"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD5ncJamH/j9iyXIEbatCXQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:01.153867Z",
          "start_time": "2019-11-05T18:28:00.404320Z"
        },
        "id": "qGqrTt5rLRd5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "8ffad085-bbc4-436e-e206-f7b13746d42b"
      },
      "source": [
        "token_counts = np.bincount([token_id for text in train_token_ids for token_id in text])\n",
        "plt.hist(token_counts, bins=100)\n",
        "plt.title('Распределение количества упоминаний токенов')\n",
        "plt.yscale('log');"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:01.204527Z",
          "start_time": "2019-11-05T18:28:01.156884Z"
        },
        "id": "uBnbU81xLRd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b44c599-75cb-4ca8-c902-215b499940b5"
      },
      "source": [
        "unknown_subwords_in_test = sum(1 for text in test_token_ids for token_id in text if token_id == 1)\n",
        "print('Количество случаев с неизвестными n-граммами символов в валидационной выборке',\n",
        "      unknown_subwords_in_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество случаев с неизвестными n-граммами символов в валидационной выборке 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHXaXI6uLReD",
        "colab_type": "text"
      },
      "source": [
        "## Подготовка датасетов для PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:02.980335Z",
          "start_time": "2019-11-05T18:28:02.938616Z"
        },
        "id": "GmymiiAbLReF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CHUNK_LENGTH = 80\n",
        "\n",
        "train_dataset = LanguageModelDataset(train_token_ids,\n",
        "                                     chunk_length=CHUNK_LENGTH)\n",
        "test_dataset = LanguageModelDataset(test_token_ids,\n",
        "                                    chunk_length=CHUNK_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:03.085890Z",
          "start_time": "2019-11-05T18:28:03.061652Z"
        },
        "scrolled": false,
        "id": "M2yS7I8PLReJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:03.260915Z",
          "start_time": "2019-11-05T18:28:03.219571Z"
        },
        "id": "W5D-Y8UnLReN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.decode(list(train_dataset[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0QF5i8cLReR",
        "colab_type": "text"
      },
      "source": [
        "## Общие классы и функции"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXlpZmxtLReT",
        "colab_type": "text"
      },
      "source": [
        "### Маска зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:04.302365Z",
          "start_time": "2019-11-05T18:28:04.244547Z"
        },
        "id": "Wuvyqf2oLReU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_target_dependency_mask(length):\n",
        "    full_mask = torch.ones(length, length)\n",
        "    ignore_mask = torch.tril(full_mask) < 1\n",
        "    full_mask.masked_fill_(ignore_mask, float('-inf'))\n",
        "    full_mask.masked_fill_(~ignore_mask, 0)\n",
        "    return full_mask\n",
        "\n",
        "make_target_dependency_mask(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t20P4AALReY",
        "colab_type": "text"
      },
      "source": [
        "### Кодирование позиции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:05.590059Z",
          "start_time": "2019-11-05T18:28:05.567602Z"
        },
        "id": "J9YqQQCeLRea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_positional_encoding(max_length, embedding_size):\n",
        "    time = np.pi * torch.arange(0, max_length).float()\n",
        "    freq_dividers = torch.arange(1, embedding_size // 2 + 1).float()\n",
        "    inputs = time[:, None] / freq_dividers[None, :]\n",
        "    \n",
        "    result = torch.zeros(max_length, embedding_size)\n",
        "    result[:, 0::2] = torch.sin(inputs)\n",
        "    result[:, 1::2] = torch.cos(inputs)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:06.060293Z",
          "start_time": "2019-11-05T18:28:05.708626Z"
        },
        "id": "y6qRdj7TLRee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_pos_codes = make_positional_encoding(30, 30)\n",
        "plt.plot(sample_pos_codes[:, ::3].numpy());\n",
        "plt.gcf().set_size_inches((15, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69rp3daQLRej",
        "colab_type": "text"
      },
      "source": [
        "### Основной класс - языковая модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:07.079279Z",
          "start_time": "2019-11-05T18:28:07.031056Z"
        },
        "id": "WzhWlOneLRel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, backbone, emb_dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "        self.backbone = backbone\n",
        "        self.out = nn.Linear(embedding_size, vocab_size)\n",
        "    \n",
        "    def forward(self, seed_token_ids):\n",
        "        \"\"\"\n",
        "            seed_token_ids - BatchSize x MaxInLen\n",
        "        \"\"\"\n",
        "        batch_size, max_in_length = seed_token_ids.shape\n",
        "\n",
        "        seed_padding_mask = seed_token_ids == 0\n",
        "        dependency_mask = make_target_dependency_mask(max_in_length) \\\n",
        "            .to(seed_token_ids.device)\n",
        "        \n",
        "        seed_embs = self.embeddings(seed_token_ids)  # BatchSize x MaxInLen x EmbSize\n",
        "        pos_codes = make_positional_encoding(max_in_length,\n",
        "                                             self.embedding_size).unsqueeze(0).to(seed_embs.device)\n",
        "        seed_embs = seed_embs + pos_codes\n",
        "        seed_embs = self.emb_dropout(seed_embs)\n",
        "\n",
        "        # BatchSize x TargetLen x EmbSize\n",
        "        target_features = seed_embs\n",
        "        target_features = self.backbone(seed_embs,\n",
        "                                        mask=dependency_mask,\n",
        "                                        src_key_padding_mask=seed_padding_mask)\n",
        "        logits = self.out(target_features)  # BatchSize x TargetLen x VocabSize\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrSzzPz5LRep",
        "colab_type": "text"
      },
      "source": [
        "### Утилиты для обучения - функция потерь и расписание изменения длины градиентного шага"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:07.797230Z",
          "start_time": "2019-11-05T18:28:07.774142Z"
        },
        "id": "ALyvpIhRLReq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lm_cross_entropy(pred, target):\n",
        "    \"\"\"\n",
        "    pred - BatchSize x TargetLen x VocabSize\n",
        "    target - BatchSize x TargetLen\n",
        "    \"\"\"\n",
        "    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n",
        "    target_flat = target.view(-1)  # BatchSize*TargetLen\n",
        "    return F.cross_entropy(pred_flat, target_flat, ignore_index=0)\n",
        "\n",
        "\n",
        "def lr_scheduler(optimizer):\n",
        "    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                      patience=20,\n",
        "                                                      factor=0.5,\n",
        "                                                      verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXEIozWrLRev",
        "colab_type": "text"
      },
      "source": [
        "## Реализация Transformer из PyTorch 1.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:09.401017Z",
          "start_time": "2019-11-05T18:28:09.365637Z"
        },
        "id": "owgcGaKPLRew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchFirstTransformerEncoder(nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.impl = nn.TransformerEncoder(*args, **kwargs)\n",
        "        self.initialize_weights()\n",
        "    \n",
        "    def forward(self, src, *args, **kwargs):\n",
        "        src = src.transpose(0, 1).contiguous()  # MaxInLen  x BatchSize x EmbSize\n",
        "        result = self.impl(src, *args, **kwargs)  # TargetLen x BatchSize x EmbSize\n",
        "        result = result.transpose(0, 1).contiguous()  # BatchSize x TargetLen x EmbSize\n",
        "        return result\n",
        "    \n",
        "    def initialize_weights(self):\n",
        "        for param in self.impl.parameters():\n",
        "            if param.dim() > 1:\n",
        "                nn.init.xavier_uniform_(param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:10.550078Z",
          "start_time": "2019-11-05T18:28:10.425261Z"
        },
        "id": "_mcuG5fsLRe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch_transf_model = LanguageModel(tokenizer.vocab_size(),\n",
        "                                   256,\n",
        "                                   BatchFirstTransformerEncoder(\n",
        "                                       nn.TransformerEncoderLayer(\n",
        "                                           d_model=256,\n",
        "                                           nhead=16,\n",
        "                                           dim_feedforward=512,\n",
        "                                           dropout=0.1),\n",
        "                                       num_layers=3),\n",
        "                                   emb_dropout=0.1)\n",
        "print('Количество параметров', get_params_number(torch_transf_model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:58.797642Z",
          "start_time": "2019-11-05T18:28:34.626744Z"
        },
        "id": "K_FaYKBXLRe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(best_val_loss,\n",
        " best_torch_transf_model) = train_eval_loop(torch_transf_model,\n",
        "                                            train_dataset,\n",
        "                                            test_dataset,\n",
        "                                            lm_cross_entropy,\n",
        "                                            lr=2e-3,\n",
        "                                            epoch_n=2000,\n",
        "                                            batch_size=8,\n",
        "                                            device='cuda',\n",
        "                                            early_stopping_patience=50,\n",
        "                                            max_batches_per_epoch_train=1000,\n",
        "                                            max_batches_per_epoch_val=1000,\n",
        "                                            lr_scheduler_ctor=lr_scheduler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:00.752077Z",
          "start_time": "2019-11-05T18:29:00.675069Z"
        },
        "id": "DLRObL75LRe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab, добавьте в начало пути /content/stepik-dl-nlp\n",
        "torch.save(best_torch_transf_model.state_dict(), './models/war_and_peace_torch_transf_best.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:00.844033Z",
          "start_time": "2019-11-05T18:29:00.789023Z"
        },
        "id": "3vVSulwjLRfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab, добавьте в начало пути /content/stepik-dl-nlp\n",
        "torch_transf_model.load_state_dict(torch.load('./models/war_and_peace_torch_transf_best.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6qkk34ALRfG",
        "colab_type": "text"
      },
      "source": [
        "## Генерация текста с помощью языковой модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3mmjPKuLRfH",
        "colab_type": "text"
      },
      "source": [
        "### Жадная генерация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:02.366423Z",
          "start_time": "2019-11-05T18:29:02.329495Z"
        },
        "id": "jgZ1nv_GLRfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "greedy_generator = GreedyGenerator(torch_transf_model, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:03.175509Z",
          "start_time": "2019-11-05T18:29:02.921960Z"
        },
        "id": "q2NUXzcNLRfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "print(greedy_generator('сказала княжна, оглядывая Бона'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:03.497702Z",
          "start_time": "2019-11-05T18:29:03.177598Z"
        },
        "id": "Aq67Y2goLRfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(greedy_generator('смеялась княжна, оглядывая Наполе'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:03.770265Z",
          "start_time": "2019-11-05T18:29:03.500330Z"
        },
        "id": "rMdkOeL0LRfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(greedy_generator('сказала княжна, оглядывая Кутуз'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:04.150676Z",
          "start_time": "2019-11-05T18:29:03.773669Z"
        },
        "id": "Nih1FtL0LRfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(greedy_generator('сказал Кутузов, оглядывая Наполеона'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag_qy-ElLRfl",
        "colab_type": "text"
      },
      "source": [
        "### Генерация с помощью лучевого поиска - Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:08.328662Z",
          "start_time": "2019-11-05T18:29:08.294006Z"
        },
        "id": "rTtxtR6yLRfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beam_generator = BeamGenerator(torch_transf_model, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:10.573399Z",
          "start_time": "2019-11-05T18:29:09.653198Z"
        },
        "id": "pkYcL9meLRfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "beam_gen_variants = beam_generator('сказала княжна, оглядывая Наполе',\n",
        "                                   beamsize=5,\n",
        "                                   return_hypotheses_n=5)\n",
        "\n",
        "for score, pred_txt in beam_gen_variants:\n",
        "    print('****')\n",
        "    print(score)\n",
        "    print(pred_txt)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:05.050342Z",
          "start_time": "2019-11-05T18:27:05.005Z"
        },
        "scrolled": false,
        "id": "Z0Qs_sjJLRfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "beam_gen_variants = beam_generator('сказала княжна, оглядывая Наполе',\n",
        "                                   beamsize=20,\n",
        "                                   return_hypotheses_n=20)\n",
        "\n",
        "for score, pred_txt in beam_gen_variants:\n",
        "    print('****')\n",
        "    print(score)\n",
        "    print(pred_txt)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:05.051378Z",
          "start_time": "2019-11-05T18:27:05.008Z"
        },
        "id": "vTuvSlNwLRfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "beam_gen_variants = beam_generator('сказала княжна, оглядывая Наполе',\n",
        "                                   beamsize=100,\n",
        "                                   return_hypotheses_n=20)\n",
        "\n",
        "for score, pred_txt in beam_gen_variants:\n",
        "    print('****')\n",
        "    print(score)\n",
        "    print(pred_txt)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH2nda15LRfy",
        "colab_type": "text"
      },
      "source": [
        "## Собственная реализация MultiHeadAttention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:13.586871Z",
          "start_time": "2019-11-05T18:29:13.544216Z"
        },
        "id": "0GDoBe3mLRf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_multihead_attention(queries, keys, values,\n",
        "                           keys_padding_mask, dependency_mask,\n",
        "                           is_training,\n",
        "                           weights_dropout):\n",
        "    \"\"\"\n",
        "    queries - BatchSize x ValuesLen x HeadN x KeySize\n",
        "    keys - BatchSize x KeysLen x HeadN x KeySize\n",
        "    values - BatchSize x KeysLen x HeadN x ValueSize\n",
        "    keys_padding_mask - BatchSize x KeysLen\n",
        "    dependency_mask - ValuesLen x KeysLen\n",
        "    is_training - bool\n",
        "    weights_dropout - float\n",
        "    \n",
        "    result - tuple of two:\n",
        "        - BatchSize x ValuesLen x HeadN x ValueSize - resulting features\n",
        "        - BatchSize x ValuesLen x KeysLen x HeadN - attention map\n",
        "    \"\"\"\n",
        "\n",
        "    # BatchSize x ValuesLen x KeysLen x HeadN\n",
        "    relevances = torch.einsum('bvhs,bkhs->bvkh', (queries, keys))\n",
        "    \n",
        "    # замаскировать элементы, выходящие за длины последовательностей ключей\n",
        "    padding_mask_expanded = keys_padding_mask[:, None, :, None].expand_as(relevances)\n",
        "    relevances.masked_fill_(padding_mask_expanded, float('-inf'))\n",
        "    \n",
        "    # замаскировать пары <выходная позиция, входная позиция>\n",
        "    relevances = relevances + dependency_mask[None, :, :, None].expand_as(relevances)\n",
        "    \n",
        "    normed_rels = F.softmax(relevances, dim=2)    \n",
        "    normed_rels = F.dropout(normed_rels, weights_dropout, is_training)\n",
        "    \n",
        "    # BatchSize x ValuesLen x KeysLen x HeadN x 1\n",
        "    normed_rels_expanded = normed_rels.unsqueeze(-1)\n",
        "    \n",
        "    # BatchSize x 1 x KeysLen x HeadN x ValueSize\n",
        "    values_expanded = values.unsqueeze(1)\n",
        "    \n",
        "    # BatchSize x ValuesLen x KeysLen x HeadN x ValueSize\n",
        "    weighted_values = normed_rels_expanded * values_expanded\n",
        "    result = weighted_values.sum(2)  # BatchSize x ValuesLen x HeadN x ValueSize\n",
        "    \n",
        "    return result, normed_rels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VnBHEpLLRf5",
        "colab_type": "text"
      },
      "source": [
        "## Self-Attention - это Attention, в котором ключи, значения и запросы вычисляются из элементов одной и той же последовательности"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:14.090216Z",
          "start_time": "2019-11-05T18:29:14.064361Z"
        },
        "id": "xDvzYUlXLRf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyMultiheadSelfAttention(nn.Module):\n",
        "    def __init__(self, model_size, n_heads, dropout=0):\n",
        "        super().__init__()\n",
        "        assert model_size % n_heads == 0, 'Размерность модели должна делиться нацело на количество голов'\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.queries_proj = nn.Linear(model_size, model_size)\n",
        "        self.keys_proj = nn.Linear(model_size, model_size)\n",
        "        self.values_proj = nn.Linear(model_size, model_size)\n",
        "        \n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.last_attention_map = None\n",
        "    \n",
        "    def forward(self, sequence, padding_mask, dependency_mask):\n",
        "        \"\"\"\n",
        "        sequence - BatchSize x Len x ModelSize\n",
        "        padding_mask - BatchSize x Len\n",
        "        dependency_mask - Len x Len\n",
        "        \n",
        "        result - BatchSize x Len x ModelSize\n",
        "        \"\"\"\n",
        "        batch_size, max_len, model_size = sequence.shape\n",
        "        \n",
        "        queries_flat = self.queries_proj(sequence)  # BatchSize x Len x ModelSize\n",
        "        queries = queries_flat.view(batch_size, max_len, self.n_heads, -1)\n",
        "        \n",
        "        keys_flat = self.keys_proj(sequence)  # BatchSize x Len x ModelSize\n",
        "        keys = keys_flat.view(batch_size, max_len, self.n_heads, -1)\n",
        "        \n",
        "        values_flat = self.values_proj(sequence)  # BatchSize x Len x ModelSize\n",
        "        values = values_flat.view(batch_size, max_len, self.n_heads, -1)\n",
        "        \n",
        "        # BatchSize x Len x HeadsN x ValueSize\n",
        "        result, att_map = my_multihead_attention(queries, keys, values,\n",
        "                                                 padding_mask, dependency_mask,\n",
        "                                                 self.training, self.dropout)\n",
        "        result_flat = result.view(batch_size, max_len, model_size)\n",
        "        \n",
        "        self.last_attention_map = att_map.detach()\n",
        "\n",
        "        return result_flat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDjRfS82LRgB",
        "colab_type": "text"
      },
      "source": [
        "## Один слой трансформера - Self-Attention, Feed-Forward, skip-connections, LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:15.069352Z",
          "start_time": "2019-11-05T18:29:15.028453Z"
        },
        "id": "2nCCDiZnLRgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyTransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, model_size, n_heads, dim_feedforward, dropout):\n",
        "        super().__init__()\n",
        "        self.self_attention = MyMultiheadSelfAttention(model_size,\n",
        "                                                       n_heads,\n",
        "                                                       dropout=dropout)\n",
        "        self.first_dropout = nn.Dropout(dropout)\n",
        "        self.first_norm = nn.LayerNorm(model_size)\n",
        "        \n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(model_size, dim_feedforward),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim_feedforward, model_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.second_norm = nn.LayerNorm(model_size)\n",
        "    \n",
        "    def forward(self, sequence, padding_mask, dependency_mask):\n",
        "        att_features = self.self_attention(sequence, padding_mask, dependency_mask)\n",
        "\n",
        "        sequence = sequence + self.first_dropout(att_features)\n",
        "        sequence = self.first_norm(sequence)\n",
        "        \n",
        "        sequence = sequence + self.feedforward(sequence)\n",
        "        sequence = self.second_norm(sequence)\n",
        "        return sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmo8_67pLRgF",
        "colab_type": "text"
      },
      "source": [
        "## Энкодер Трансформера - стопка из нескольких слоёв"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:15.728916Z",
          "start_time": "2019-11-05T18:29:15.680640Z"
        },
        "id": "cN6SjgsYLRgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyTransformerEncoder(nn.Module):\n",
        "    def __init__(self, n_layers, **layer_kwargs):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            MyTransformerEncoderLayer(**layer_kwargs)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def forward(self, sequence, mask, src_key_padding_mask):\n",
        "        for layer in self.layers:\n",
        "            sequence = layer(sequence, src_key_padding_mask, mask)\n",
        "        return sequence\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for param in self.parameters():\n",
        "            if param.dim() > 1:\n",
        "                nn.init.xavier_uniform_(param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thg3Wq1lLRgO",
        "colab_type": "text"
      },
      "source": [
        "## Попробуем обучить языковую модель с нашим Трансформером"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:18.531896Z",
          "start_time": "2019-11-05T18:29:18.460196Z"
        },
        "id": "l7sW6OjSLRgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_transf_model = LanguageModel(tokenizer.vocab_size(),\n",
        "                                256,\n",
        "                                MyTransformerEncoder(\n",
        "                                    n_layers=3,\n",
        "                                    model_size=256,\n",
        "                                    n_heads=16,\n",
        "                                    dim_feedforward=512,\n",
        "                                    dropout=0.1),\n",
        "                                emb_dropout=0.1)\n",
        "print('Количество параметров', get_params_number(my_transf_model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:30.000482Z",
          "start_time": "2019-11-05T18:29:24.291741Z"
        },
        "scrolled": true,
        "id": "bITlX6TPLRgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(best_val_loss,\n",
        " best_my_transf_model) = train_eval_loop(my_transf_model,\n",
        "                                         train_dataset,\n",
        "                                         test_dataset,\n",
        "                                         lm_cross_entropy,\n",
        "                                         lr=2e-3,\n",
        "                                         epoch_n=2000,\n",
        "                                         batch_size=8,\n",
        "                                         device='cuda',\n",
        "                                         early_stopping_patience=50,\n",
        "                                         max_batches_per_epoch_train=1000,\n",
        "                                         max_batches_per_epoch_val=1000,\n",
        "                                         lr_scheduler_ctor=lr_scheduler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:30.732005Z",
          "start_time": "2019-11-05T18:29:30.686738Z"
        },
        "id": "w_IGrqqRLRga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab, добавьте в начало пути /content/stepik-dl-nlp\n",
        "torch.save(best_my_transf_model.state_dict(), './models/war_and_peace_my_transf_best.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:30.853057Z",
          "start_time": "2019-11-05T18:29:30.811442Z"
        },
        "id": "tdzJUb9WLRgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Если Вы запускаете ноутбук на colab, добавьте в начало пути /content/stepik-dl-nlp\n",
        "my_transf_model.load_state_dict(torch.load('./models/war_and_peace_my_transf_best.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSbSBMtpLRgj",
        "colab_type": "text"
      },
      "source": [
        "## Наша реализация - жадная генерация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:31.862429Z",
          "start_time": "2019-11-05T18:29:31.841831Z"
        },
        "id": "3UpzZEDBLRgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_greedy_generator = GreedyGenerator(my_transf_model, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:32.263263Z",
          "start_time": "2019-11-05T18:29:31.988891Z"
        },
        "id": "v7J5843XLRgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_greedy_generator('сказала княжна, оглядывая Андре')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET7Q-hdlLRgt",
        "colab_type": "text"
      },
      "source": [
        "## Визуализация карт внимания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:33.644923Z",
          "start_time": "2019-11-05T18:29:33.614615Z"
        },
        "id": "YzJZtHorLRgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_attention_maps(model, input_string, tokenizer, device='cuda', max_heads=2, figsize=(16, 10)):\n",
        "    device = torch.device(device)\n",
        "\n",
        "    token_ids = tokenizer.encode([input_string])[0]\n",
        "\n",
        "    token_strs = [tokenizer.id_to_subword(i) for i in token_ids]\n",
        "    in_len = len(token_ids)\n",
        "    ticks = np.arange(0, in_len)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    in_batch = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
        "    model(in_batch)\n",
        "\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, MyMultiheadSelfAttention):\n",
        "            cur_last_attention_map = module.last_attention_map[0].cpu().numpy()\n",
        "            n_heads = cur_last_attention_map.shape[-1]\n",
        "            n_heads_to_vis = min(n_heads, max_heads)\n",
        "\n",
        "            fig, axes = plt.subplots(1, n_heads_to_vis)\n",
        "            fig.set_size_inches(figsize)\n",
        "            for head_i in range(n_heads_to_vis):\n",
        "                ax = axes[head_i]\n",
        "                ax.imshow(cur_last_attention_map[..., head_i])\n",
        "\n",
        "                ax.set_yticks(ticks)\n",
        "                ax.set_ylim(bottom=in_len - 0.5, top=-0.5)\n",
        "                ax.set_yticklabels(token_strs)\n",
        "\n",
        "                ax.set_xticks(ticks)\n",
        "                ax.set_xticklabels(token_strs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:34.935250Z",
          "start_time": "2019-11-05T18:29:33.745970Z"
        },
        "id": "fjsyDBdmLRgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_attention_maps(my_transf_model, 'сказал Кутузов, оглядывая Бонапарта', tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJMQadbZLRgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}